{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## Introduction\n",
    "\n",
    "### Variable Stars\n",
    "\n",
    "While most stars emit steady light, some show periodic variations in brightness—these are called [**variable stars**](http://en.wikipedia.org/wiki/Variable_star). Variability arises due to intrinsic pulsations or because the star is part of a [**binary system**](http://en.wikipedia.org/wiki/Binary_system) that causes eclipses. Studying such stars is vital for measuring cosmic distances. With upcoming surveys like [LSST](http://www.lsst.org/lsst), automating their analysis is increasingly important.\n",
    "\n",
    "### The EROS1 Database\n",
    "\n",
    "Our dataset comes from the [**EROS1 project**](http://eros.in2p3.fr/), which captured 400 photographic plates (1990–1994) of the [Large Magellanic Cloud](http://en.wikipedia.org/wiki/Large_Magellanic_Cloud) using the ESO-Schmidt 1m telescope. Each plate, covering a 5°×5° field, was taken in two bands (red: 630nm, blue: 385nm), digitized in Paris, and analyzed at IN2P3.\n",
    "\n",
    "### Variable Star Selection\n",
    "\n",
    "Out of 8 million stars, \\~1% were flagged as unstable by an algorithm. These were manually labeled into types: **RR-Lyrae, Cepheid, Eclipsing Binary, Mira**, or **Other**. A total of **22,802** variables were found, reduced to **19,429** after data cleaning.\n",
    "\n",
    "### Dataset Used\n",
    "\n",
    "For modeling, “unclassified” types were excluded, and 30% of the remaining data (3,641 instances) was used for training. The dataset includes:\n",
    "\n",
    "* [`train.csv`] static features\n",
    "* [`train_varlength_features.csv.gz`] variable-length time series features (loaded via `get_train_data`)\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import chain\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get access to the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'problem'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mproblem\u001b[39;00m\n\u001b[0;32m      3\u001b[0m X_df, y \u001b[38;5;241m=\u001b[39m problem\u001b[38;5;241m.\u001b[39mget_train_data()\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'problem'"
     ]
    }
   ],
   "source": [
    "import problem\n",
    "\n",
    "X_df, y = problem.get_train_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The static features\n",
    "\n",
    "<span style=\"color:red\">Red variables</span> are ids, labels, or other human-annotated features, so they should not be used as input in the classification. <span style=\"color:lightblue\">Light blue variables</span> are legal but not likely to contribute information to the classification. Black variables are definitely discriminative.\n",
    "\n",
    "<ul>\n",
    "    <li> <code><b><span style=\"color:red\">patch_id</span></b></code>: The catalogue is organized by tiles corresponding to 1 cm<sup>2</sup> patches on the plates, this is their id.\n",
    "    <li> <code><b><span style=\"color:red\">star_id_b, star_id_r</span></b></code>: The id of the star within the patch. <code>patch_id</code> and <code>star_id_b</code> or <code>star_id_r</code> identify the stars uniquely, and we use <code>[patch_id]_[star_id_b]</code> for indexing the stars in the pandas table.\n",
    "    <li> <code><b>magnitude_b, magnitude_r</b></code>: The average apparent luminosity of the star (in two frequency bands). <a href=\"http://www.astro-tom.com/technical_data/magnitude_scale.htm\">Magnitude</a> is a logarithmic measure, and the higher it is, the lower the apparent luminosity is.\n",
    "    <li> <code><b><span style=\"color:lightblue\">asc_d, asc_m, asc_s</span></b></code>: <a href=\"http://en.wikipedia.org/wiki/Celestial_coordinate_system\">Celestial</a> <a href=\"http://en.wikipedia.org/wiki/Right_ascension\">right ascension</a> (coordinate) of the star, measured in degrees, minutes, and seconds, respectively.\n",
    "    <li> <code><b><span style=\"color:lightblue\">dec_d, dec_m, dec_s</span></b></code>: <a href=\"http://en.wikipedia.org/wiki/Celestial_coordinate_system\">Celestial</a> <a href=\"http://en.wikipedia.org/wiki/Declination\">declination</a> (coordinate) of the star, measured in degrees, minutes, and seconds, respectively.\n",
    "    <li> <code><b><span style=\"color:black\">period</span></b></code>: the estimated period of the light curve. For the correct period, it should be divided by <code>div_period</code>\n",
    "    <li> <code><b><span style=\"color:lightblue\">frequency</span></b></code>: $1/$<code>period</code>, so it is redundant.\n",
    "    <li> <code><b><span style=\"color:lightblue\">num_points_good_b, num_points_good_r</span></b></code>: Number of good light curve measurements (some measurements can be corrupted). \n",
    "    <li> <code><b><span style=\"color:black\">asym_b, asym_r</span></b></code>: Unknown semantics.\n",
    "    <li> <code><b><span style=\"color:black\">log_p_not_variable</span></b></code>: Logarithm of the estimated probability that the star is stable.\n",
    "    <li> <code><b><span style=\"color:black\">sigma_flux_b, sigma_flux_r</span></b></code>: The square root of the total variance of the light measurements (indicating the amplitude of the variability).\n",
    "    <li> <code><b><span style=\"color:red\">type</span></b></code>: The label to predict.\n",
    "    <li> <code><b><span style=\"color:red \">quality</span></b></code>: Human-annotated measure of the quality of the time curve. The higher the better.\n",
    "    <li> <code><b><span style=\"color:black \">div_period</span></b></code>: The algorithm that estimates the <code>period</code> sometimes finds a multiple of the period. These cases were human-detected, and the divisor was recorded. In principle this variable is not available automatically as an observable, but we are confident that it could be obtained automatically, so we allow it as an input.\n",
    "</ul> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m X_df\u001b[38;5;241m.\u001b[39mhead()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_df' is not defined"
     ]
    }
   ],
   "source": [
    "X_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names = {1: 'binary', 2: 'cepheid', 3: 'rr_lyrae', 4: 'mira'}\n",
    "labels = list(label_names.keys())\n",
    "y_series = pd.Series(y).replace(label_names)\n",
    "y_series.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = y_series.value_counts().plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some classwise histograms and scatterplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['r', 'b', 'g', 'm']\n",
    "def plot_classwise_normalized(feature, bins=None):\n",
    "    if bins is None:\n",
    "        bins = np.linspace(X_df[feature].min(), X_df[feature].max(), 15)\n",
    "    for label, color in zip(labels, colors):\n",
    "        plt.hist(X_df[y == label][feature].values, density=True, bins=bins, \n",
    "                 alpha=0.5, color=color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_classwise_normalized('period')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_classwise_normalized('period', bins=np.linspace(0, 50, 15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe the aliasing below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_classwise_normalized('period', bins=np.linspace(0, 5, 15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df['real_period'] = X_df['period'] / X_df['div_period']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_classwise_normalized('real_period')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_classwise_normalized('real_period', bins=np.linspace(0, 50, 15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_classwise_normalized('real_period', bins=np.linspace(0, 5, 15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_classwise_normalized('magnitude_b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_classwise_normalized('magnitude_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_classwise_normalized('asym_b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_classwise_normalized('asym_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_classwise_normalized('sigma_flux_b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_classwise_normalized('sigma_flux_b', bins=np.linspace(0, 1000, 15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_classwise_normalized('sigma_flux_b', bins=np.linspace(0, 100, 15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_classwise_normalized('sigma_flux_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_classwise_normalized('sigma_flux_r', bins=np.linspace(0, 1000, 15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_classwise_normalized('sigma_flux_r', bins=np.linspace(0, 100, 15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_classwise_normalized('log_p_not_variable')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['r', 'b', 'g', 'm']\n",
    "def plot_classwise_scatter(feature1, feature2, range1=None, range2=None):\n",
    "    if range1 is None:\n",
    "        range1 = [X_df[feature1].min(), X_df[feature1].max()]\n",
    "    if range2 is None:\n",
    "        range2 = [X_df[feature2].min(), X_df[feature2].max()]\n",
    "    for label, color in zip(labels, colors):\n",
    "        plt.xlim(range1[0], range1[1])\n",
    "        plt.ylim(range2[0], range2[1])\n",
    "        plt.scatter(X_df[y == label][feature1], \n",
    "                    X_df[y == label][feature2],\n",
    "            alpha=0.3, s=80, c=color, marker='.');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_classwise_scatter('magnitude_b', 'magnitude_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_classwise_scatter('magnitude_b', 'real_period', range1=None, range2=[0,10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The time series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each column contains a list of floating point numbers.\n",
    "\n",
    "<ul>\n",
    "    <li> <code><b><span style=\"color:black\">time_points_b, time_points_r</span></b></code>: The time (in unit of days) when the photos were taken. Note that the filters had to be changed so the time points of the blue and red frequency band are slighty different.\n",
    "    <li> <code><b><span style=\"color:black\">light_points_b, light_points_r</span></b></code>: The light points measured at the time points.\n",
    "    <li> <code><b><span style=\"color:black\">error_points_b, error_points_r</span></b></code>: Uncertainties (error bars) on the light measurements.\n",
    "    <li> <code><b><span style=\"color:lightblue\">bkg_points_, bkg_points_r</span></b></code>: Background noise measured at the time points.\n",
    "    <li> <code><b><span style=\"color:lightblue\">polltn_points_b, polltn_points_r</span></b></code>: Pollution noise measured at the time points.\n",
    "</ul> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df.hist('num_points_good_r')\n",
    "print(min(X_df['num_points_good_b']))\n",
    "print(max(X_df['num_points_good_b']))\n",
    "print(min(X_df['num_points_good_r']))\n",
    "print(max(X_df['num_points_good_r']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting time curves\n",
    "\n",
    "Set the patch id and star id below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_id = 98\n",
    "star_id_b = 477\n",
    "\n",
    "def star_key(slab_id, star_id_b):\n",
    "    return str(slab_id) + '_' + str(star_id_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df = X_df.set_index(X_df.apply(lambda row: \"%d_%d\" % (row['patch_id'], row['star_id_b']), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_points = X_df.loc[star_key(patch_id, star_id_b)]['time_points_b']\n",
    "light_points = X_df.loc[star_key(patch_id, star_id_b)]['light_points_b']\n",
    "error_points = X_df.loc[star_key(patch_id, star_id_b)]['error_points_b']\n",
    "plt.errorbar(time_points, light_points, yerr=error_points, fmt='o');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The raw measurements seem rather messy. The scatter of the plots is visibly larger than the measurement uncertainty (which makes it, by definition, a variable star), but there is no visible periodicity. We can use the estimated period to overplot several periods of the curve (\"fold\" the time series) using the following function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fold_time_series(time_point, period, div_period):\n",
    "    real_period = period / div_period\n",
    "    return time_point % real_period  # modulo real_period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "period = X_df.loc[star_key(patch_id, star_id_b)]['period']\n",
    "div_period = X_df.loc[star_key(patch_id, star_id_b)]['div_period']\n",
    "print(period, div_period)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_points_folded = [fold_time_series(time_point, period, div_period) \n",
    "                      for time_point in time_points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting curve has a characteristic signature. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.gca().invert_yaxis()\n",
    "plt.errorbar(time_points_folded, light_points, yerr=error_points, fmt='o');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The feature extractor\n",
    "\n",
    "The input data are stored in a dataframe. To go from a dataframe to a numpy array we will\n",
    "a scikit-learn column transformer. The first example we will write will just consist in\n",
    "selecting a subset of columns we want to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\n",
    "    'magnitude_b', \n",
    "    'magnitude_r',\n",
    "    'period',\n",
    "    'asym_b', \n",
    "    'asym_r', \n",
    "    'log_p_not_variable', \n",
    "    'sigma_flux_b', \n",
    "    'sigma_flux_r', \n",
    "    'quality', \n",
    "    'div_period',\n",
    "]\n",
    "\n",
    "from sklearn.compose import make_column_transformer\n",
    "\n",
    "transformer = make_column_transformer(\n",
    "    ('passthrough', cols)\n",
    ")\n",
    "\n",
    "X_array = transformer.fit_transform(X_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at how to transform line curves.\n",
    "\n",
    "The following feature extractor takes the light curve, bins it into <code>num_bins</code> bins, and return the bin means. It works with one band at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fold_time_series(time_point, period, div_period):\n",
    "    return (time_point -\n",
    "            (time_point // (period / div_period)) * period / div_period)\n",
    "\n",
    "\n",
    "def get_bin_means(X_df, num_bins, band):\n",
    "    feature_array = np.empty((len(X_df), num_bins))\n",
    "\n",
    "    for k, (_, x) in enumerate(X_df.iterrows()):\n",
    "        period = x['period']\n",
    "        div_period = x['div_period']\n",
    "        real_period = period / div_period\n",
    "        bins = [i * real_period / num_bins for i in range(num_bins + 1)]\n",
    "\n",
    "        time_points = np.array(x['time_points_' + band])\n",
    "        light_points = np.array(x['light_points_' + band])\n",
    "        time_points_folded = \\\n",
    "            np.array([fold_time_series(time_point, period, div_period)\n",
    "                      for time_point in time_points])\n",
    "        time_points_folded_digitized = \\\n",
    "            np.digitize(time_points_folded, bins) - 1\n",
    "\n",
    "        for i in range(num_bins):\n",
    "            this_light_points = light_points[time_points_folded_digitized == i]\n",
    "            if len(this_light_points) > 0:\n",
    "                feature_array[k, i] = np.mean(this_light_points)\n",
    "            else:\n",
    "                feature_array[k, i] = np.nan  # missing\n",
    "\n",
    "    return feature_array\n",
    "\n",
    "\n",
    "get_bin_means(X_df.iloc[:2], 5, 'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this we will use a funtion transformer that will get applied to both red and blues curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "transformer_r = FunctionTransformer(\n",
    "    lambda X_df: get_bin_means(X_df, 5, 'r')\n",
    ")\n",
    "\n",
    "transformer_b = FunctionTransformer(\n",
    "    lambda X_df: get_bin_means(X_df, 5, 'b')\n",
    ")\n",
    "\n",
    "transformer = make_column_transformer(\n",
    "    (transformer_r, ['period', 'div_period', 'time_points_r', 'light_points_r']),\n",
    "    (transformer_b, ['period', 'div_period', 'time_points_b', 'light_points_b']),\n",
    ")\n",
    "\n",
    "X_array = transformer.fit_transform(X_df)\n",
    "X_array.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combined with some static features and plugged into a random forest it reads;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "def fold_time_series(time_point, period, div_period):\n",
    "    return (time_point -\n",
    "            (time_point // (period / div_period)) * period / div_period)\n",
    "\n",
    "\n",
    "def get_bin_means(X_df, num_bins, band):\n",
    "    feature_array = np.empty((len(X_df), num_bins))\n",
    "\n",
    "    for k, (_, x) in enumerate(X_df.iterrows()):\n",
    "        period = x['period']\n",
    "        div_period = x['div_period']\n",
    "        real_period = period / div_period\n",
    "        bins = [i * real_period / num_bins for i in range(num_bins + 1)]\n",
    "\n",
    "        time_points = np.array(x['time_points_' + band])\n",
    "        light_points = np.array(x['light_points_' + band])\n",
    "        time_points_folded = \\\n",
    "            np.array([fold_time_series(time_point, period, div_period)\n",
    "                      for time_point in time_points])\n",
    "        time_points_folded_digitized = \\\n",
    "            np.digitize(time_points_folded, bins) - 1\n",
    "\n",
    "        for i in range(num_bins):\n",
    "            this_light_points = light_points[time_points_folded_digitized == i]\n",
    "            if len(this_light_points) > 0:\n",
    "                feature_array[k, i] = np.mean(this_light_points)\n",
    "            else:\n",
    "                feature_array[k, i] = np.nan  # missing\n",
    "\n",
    "    return feature_array\n",
    "\n",
    "\n",
    "transformer_r = FunctionTransformer(\n",
    "    lambda X_df: get_bin_means(X_df, 5, 'r')\n",
    ")\n",
    "\n",
    "transformer_b = FunctionTransformer(\n",
    "    lambda X_df: get_bin_means(X_df, 5, 'b')\n",
    ")\n",
    "\n",
    "cols = [\n",
    "    'magnitude_b',\n",
    "    'magnitude_r',\n",
    "    'period',\n",
    "    'asym_b',\n",
    "    'asym_r',\n",
    "    'log_p_not_variable',\n",
    "    'sigma_flux_b',\n",
    "    'sigma_flux_r',\n",
    "    'quality',\n",
    "    'div_period',\n",
    "]\n",
    "\n",
    "common = ['period', 'div_period']\n",
    "transformer = make_column_transformer(\n",
    "    (transformer_r, common + ['time_points_r', 'light_points_r']),\n",
    "    (transformer_b, common + ['time_points_b', 'light_points_b']),\n",
    "    ('passthrough', cols)\n",
    ")\n",
    "\n",
    "pipe = make_pipeline(\n",
    "    transformer,\n",
    "    SimpleImputer(strategy='most_frequent'),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10)\n",
    ")\n",
    "\n",
    "\n",
    "def get_estimator():\n",
    "    return pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing using a scikit-learn pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import problem\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "X_df, y = problem.get_train_data()\n",
    "\n",
    "scores = cross_val_score(get_estimator(), X_df, y, cv=2, scoring='accuracy')\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
